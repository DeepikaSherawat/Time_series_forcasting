{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4f45b5c7",
      "metadata": {
        "id": "4f45b5c7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from pandas.plotting import lag_plot\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d7523e96",
      "metadata": {
        "scrolled": true,
        "id": "d7523e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "d5221dec-b596-4910-8b09-adf2cdb4544b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-59a1f973c27e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Website Vistiors Daywise - Sheet1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Website Vistiors Daywise - Sheet1.csv'"
          ]
        }
      ],
      "source": [
        "Data = pd.read_csv(\"Website Vistiors Daywise - Sheet1.csv\")\n",
        "pd.set_option('display.max_rows', None)\n",
        "Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef1cf549",
      "metadata": {
        "scrolled": true,
        "id": "ef1cf549"
      },
      "outputs": [],
      "source": [
        "#changing from dd-mm-yyyy to yyyy-mm-dd\n",
        "import datetime\n",
        "date = list()\n",
        "for d in Data.Date.tolist():\n",
        "    t = datetime.datetime.strptime(d, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
        "    date.append(t)\n",
        "\n",
        "Data['date'] = date\n",
        "Data.drop(\"Date\", axis =1, inplace =True)\n",
        "Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "847acc3e",
      "metadata": {
        "id": "847acc3e"
      },
      "source": [
        "# EDA and data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8507592b",
      "metadata": {
        "id": "8507592b"
      },
      "outputs": [],
      "source": [
        "Data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231d58a2",
      "metadata": {
        "id": "231d58a2"
      },
      "outputs": [],
      "source": [
        "# changing the type of \"Date\" column from object to datetime\n",
        "Data[\"date\"]= pd.to_datetime(Data[\"date\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0871ef58",
      "metadata": {
        "id": "0871ef58"
      },
      "source": [
        "check for duplicate rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6318e2",
      "metadata": {
        "id": "8b6318e2"
      },
      "outputs": [],
      "source": [
        "duplicate = Data[Data.duplicated()]\n",
        "\n",
        "print(\"Duplicate Rows :\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aacda43",
      "metadata": {
        "id": "9aacda43"
      },
      "outputs": [],
      "source": [
        "Data.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9d1e00",
      "metadata": {
        "id": "4c9d1e00"
      },
      "outputs": [],
      "source": [
        "Data.columns = [\"visitors\",\"date\"]\n",
        "df = Data.set_index(\"date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd022283",
      "metadata": {
        "scrolled": false,
        "id": "bd022283"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (8,4))\n",
        "plt.subplot(211)\n",
        "sns.boxplot(df.visitors)\n",
        "plt.subplot(212)\n",
        "sns.distplot(df.visitors)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df86389f",
      "metadata": {
        "id": "df86389f"
      },
      "outputs": [],
      "source": [
        "df.loc[df['visitors']>=4500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e297be97",
      "metadata": {
        "id": "e297be97"
      },
      "outputs": [],
      "source": [
        "#repacing the outliers with median\n",
        "\n",
        "print(\"median :\", df['visitors'].quantile(0.50))\n",
        "print(df['visitors'].quantile(0.95))\n",
        "df['visitors'] = np.where(df['visitors'] > 4500, 2751, df['visitors'])\n",
        "plt.figure(figsize = (8,4))\n",
        "plt.subplot(211)\n",
        "sns.boxplot(df.visitors)\n",
        "plt.subplot(212)\n",
        "sns.distplot(df.visitors)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f7f4e5",
      "metadata": {
        "id": "00f7f4e5"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a7758b",
      "metadata": {
        "id": "15a7758b"
      },
      "outputs": [],
      "source": [
        "df['visitors'].plot(figsize=(8, 3))\n",
        "\n",
        "plt.ylabel(\"visitors\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "348b6d94",
      "metadata": {
        "id": "348b6d94"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73a938d3",
      "metadata": {
        "scrolled": true,
        "id": "73a938d3"
      },
      "outputs": [],
      "source": [
        "df['month'] = df.index.month\n",
        "df['day'] = df.index.day\n",
        "df['year'] = df.index.year\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e1f758",
      "metadata": {
        "id": "34e1f758"
      },
      "outputs": [],
      "source": [
        "# if the day is a weekend or weekday?\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "def weekend_or_weekday(year,month,day):\n",
        "\n",
        "    d = datetime(year,month,day)\n",
        "    if d.weekday()>4:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['weekend'] = df.apply(lambda x:weekend_or_weekday(x['year'], x['month'], x['day']), axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "509e62d4",
      "metadata": {
        "id": "509e62d4"
      },
      "outputs": [],
      "source": [
        "#comparing internet traffic on weekend and working day\n",
        "plt.figure(figsize = (3,3))\n",
        "sns.boxplot(x=\"weekend\",y=\"visitors\",data=df)\n",
        "plt.title(\" internet traffic on a weekend or not weekend\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff21e61",
      "metadata": {
        "id": "aff21e61"
      },
      "outputs": [],
      "source": [
        "# if the day is a holiday or not?\n",
        "from datetime import date\n",
        "import holidays\n",
        "\n",
        "def is_holiday(x):\n",
        "\n",
        "    india_holidays = holidays.country_holidays('IN')\n",
        "\n",
        "    if india_holidays.get(x):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['holidays'] = df.index.to_series().apply(is_holiday)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48e0a9e8",
      "metadata": {
        "id": "48e0a9e8"
      },
      "outputs": [],
      "source": [
        "# comparing internet traffic on holidays and non-holidays\n",
        "plt.figure(figsize = (3,3))\n",
        "plt.title(\" internet traffic on a holiday or not a holiday\")\n",
        "sns.boxplot(x=\"holidays\",y=\"visitors\",data=df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57386661",
      "metadata": {
        "id": "57386661"
      },
      "outputs": [],
      "source": [
        "# Boxplots\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.subplot(211)\n",
        "sns.boxplot(x=\"month\",y=\"visitors\",data=df,order=[10,11,12,1,2,3])\n",
        "plt.subplot(212)\n",
        "sns.boxplot(x=\"year\",y=\"visitors\",data=df)\n",
        "plt.subplots_adjust(left=0.1,bottom=0.1, right=0.9,top=0.9,wspace=0.2,hspace=0.4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f2e3a2",
      "metadata": {
        "id": "09f2e3a2"
      },
      "outputs": [],
      "source": [
        "figure, axes = plt.subplots(2, 3, figsize=(10, 5))\n",
        "sns.lineplot(ax=axes[0, 0], data = df.loc[df[\"month\"]==10].sort_values(by='day'), x='day',y='visitors')\n",
        "axes[0,0].legend([\"october\"])\n",
        "sns.lineplot(ax=axes[0, 1], data = df.loc[df[\"month\"]== 11].sort_values(by='day'), x='day',y='visitors')\n",
        "sns.lineplot(ax=axes[0, 2], data = df.loc[df[\"month\"]==12].sort_values(by='day'), x='day',y='visitors')\n",
        "sns.lineplot(ax=axes[1, 0], data = df.loc[df[\"month\"]==1].sort_values(by='day'), x='day',y='visitors')\n",
        "sns.lineplot(ax=axes[1, 1], data = df.loc[df[\"month\"]==2].sort_values(by='day'), x='day',y='visitors')\n",
        "sns.lineplot(ax=axes[1, 2], data = df.loc[df[\"month\"]==3].sort_values(by='day'), x='day',y='visitors')\n",
        "axes[0,1].legend([\"november\"])\n",
        "axes[0,2].legend([\"december\"])\n",
        "axes[1,0].legend([\"january\"])\n",
        "axes[1,1].legend([\"february\"])\n",
        "axes[1,2].legend([\"march\"])\n",
        "plt.subplots_adjust(left=0.1,bottom=0.1, right=0.9,top=0.9,wspace=0.2,hspace=0.4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70636baf",
      "metadata": {
        "id": "70636baf"
      },
      "outputs": [],
      "source": [
        "med = df.loc[df['month']==2,'visitors'].quantile(0.50)\n",
        "upper_limit = df.loc[df['month']==2,'visitors'].quantile(0.95)\n",
        "print('median : ', med)\n",
        "print('upper limit : ', upper_limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6127bb86",
      "metadata": {
        "id": "6127bb86"
      },
      "outputs": [],
      "source": [
        "#repacing the outliers in feb with median\n",
        "med = df.loc[df['month']==2,'visitors'].quantile(0.50)\n",
        "upper_limit = df.loc[df['month']==2,'visitors'].quantile(0.95)\n",
        "df.loc[df['month']==2,'visitors'] = np.where(df.loc[df['month']==2,'visitors'] > upper_limit, med,\n",
        "                                             df.loc[df['month']==2,'visitors'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd03e317",
      "metadata": {
        "id": "fd03e317"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "for i in [1,10,14,50]:\n",
        "    df[\"visitors\"].rolling(i).mean().plot(label=str(i))\n",
        "\n",
        "plt.legend(loc=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fcc5e02",
      "metadata": {
        "scrolled": false,
        "id": "4fcc5e02"
      },
      "outputs": [],
      "source": [
        "ts_mul = seasonal_decompose(df.visitors,model=\"multiplicative\", period =50)\n",
        "fig = ts_mul.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f4f95c1",
      "metadata": {
        "id": "4f4f95c1"
      },
      "outputs": [],
      "source": [
        "ts_mul = seasonal_decompose(df.visitors,model=\"additive\", period =50)\n",
        "fig = ts_mul.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5263240",
      "metadata": {
        "id": "b5263240"
      },
      "outputs": [],
      "source": [
        "# Tail-rolling average transform\n",
        "rolling = df.visitors.rolling(window=2)\n",
        "rolling_mean = rolling.mean()\n",
        "print(rolling_mean.head())\n",
        "# plot original and transformed dataset\n",
        "plt.figure(figsize = (8,4))\n",
        "df.visitors.plot()\n",
        "rolling_mean.plot(color='red')\n",
        "plt.legend(['actual time series','transformed time series'])\n",
        "plt.ylabel(\"no. of visitors\")\n",
        "plt.xlabel(\"observation\")\n",
        "plt.show()\n",
        "df1 = pd.DataFrame(rolling_mean.dropna())\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4271de",
      "metadata": {
        "scrolled": true,
        "id": "fb4271de"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (8,3))\n",
        "axes = lag_plot(df.visitors)\n",
        "lag_plot(df1.visitors,ax=axes, c = 'orange' )\n",
        "plt.legend(['Raw data', 'Tail-rolling average(window=2)'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d07abd",
      "metadata": {
        "id": "59d07abd"
      },
      "source": [
        "**A lag plot checks whether a data set or time series is random or not. Random data should not exhibit any identifiable structure in the lag plot. Non-random structure in the lag plot indicates that the underlying data are not random.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ac96908",
      "metadata": {
        "scrolled": true,
        "id": "1ac96908"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(10,3))\n",
        "plot_acf(df1.visitors,lags=100,ax = ax[0])\n",
        "plot_pacf(df1.visitors,lags=50, ax = ax[1])\n",
        "plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1,\n",
        "                    right=0.9,\n",
        "                    top=0.9,\n",
        "                    wspace=0.3,\n",
        "                    hspace=0.4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a11c56",
      "metadata": {
        "id": "64a11c56"
      },
      "outputs": [],
      "source": [
        "# Dickey_fuller test to check if the series is stationary or non-stationary\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "res = adfuller(df1.visitors,autolag='AIC')\n",
        "print('Augmneted Dickey_fuller Statistic: %f' % res[0])\n",
        "print('p-value: %f' % res[1])\n",
        "print('Lags: %f' % res[2])\n",
        "# printing the critical values at different alpha levels.\n",
        "print('critical values at different levels:')\n",
        "for k, v in res[4].items():\n",
        "    print('\\t%s: %.3f' % (k, v))\n",
        "print(f'Result: The series is {\"not \" if res[1] > 0.05 else \"\"}stationary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a06ecf",
      "metadata": {
        "id": "f0a06ecf"
      },
      "outputs": [],
      "source": [
        "#Kwiatkowski-Phillips-Schmidt-Shin(KPSS) test to check if the series is trend stationary\n",
        "from statsmodels.tsa.stattools import kpss\n",
        "def kpss_test(series, **kw):\n",
        "    statistic, p_value, n_lags, critical_values = kpss(series, **kw)\n",
        "    # Format Output\n",
        "    print(f'KPSS Statistic: {statistic}')\n",
        "    print(f'p-value: {p_value}')\n",
        "    print(f'num lags: {n_lags}')\n",
        "    print('Critial Values:')\n",
        "    for key, value in critical_values.items():\n",
        "        print(f'   {key} : {value}')\n",
        "    print(f'Result: The series is {\"not \" if p_value < 0.05 else \"\"}stationary')\n",
        "\n",
        "kpss_test(df1, regression=\"ct\", nlags=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c88ae347",
      "metadata": {
        "id": "c88ae347"
      },
      "source": [
        "**the series has both trend and seasonality and this is why showing not stationary in ADF test but not stationary around the deterministic tred in the KPSS test.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eadeea1",
      "metadata": {
        "id": "0eadeea1"
      },
      "source": [
        "# Preparing Dataset for modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a77385",
      "metadata": {
        "scrolled": true,
        "id": "e1a77385"
      },
      "outputs": [],
      "source": [
        "from numpy import log\n",
        "df1[\"log_visitors\"] = log(df1[\"visitors\"])\n",
        "df1['t'] = range(1,(len(df1[\"visitors\"])+1))\n",
        "df1['t_sq'] = df1['t']**2\n",
        "df1['month'] = df1.index.month\n",
        "df1['day'] = df1.index.day\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2543d903",
      "metadata": {
        "id": "2543d903"
      },
      "outputs": [],
      "source": [
        "#splitting the time series obtained after transformation\n",
        "X = df1.visitors\n",
        "train, test = np.split(X, [int(.67 *len(X))])\n",
        "print(\"train dimensions\", train.shape)\n",
        "print(\"test dimensions\", test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7907af0d",
      "metadata": {
        "id": "7907af0d"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4e2e50c",
      "metadata": {
        "id": "f4e2e50c"
      },
      "outputs": [],
      "source": [
        "import statsmodels.formula.api as smf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83771975",
      "metadata": {
        "id": "83771975"
      },
      "outputs": [],
      "source": [
        "#Quadratic\n",
        "#splitting the data\n",
        "train1, test1 = np.split(df1, [int(.67 *len(df1))])\n",
        "Quad = smf.ols('visitors~t+t_sq',data=train1).fit()\n",
        "pred_Quad = pd.Series(Quad.predict(test1[[\"t\",\"t_sq\"]]))\n",
        "rmse_Quad = np.sqrt(np.mean((np.array(test1['visitors'])-np.array(pred_Quad))**2))\n",
        "print(rmse_Quad)\n",
        "plt.figure(figsize = (6,3))\n",
        "pred_Quad.plot()\n",
        "test1['visitors'].plot()\n",
        "plt.legend(['predicted', 'actual'],loc = (0.75,0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbad1508",
      "metadata": {
        "id": "bbad1508"
      },
      "outputs": [],
      "source": [
        "#Exponential\n",
        "\n",
        "Exp = smf.ols('log_visitors~t',data=train1).fit()\n",
        "pred_Exp = pd.Series(Exp.predict(test1[[\"t\",\"t_sq\"]]))\n",
        "rmse_Exp = np.sqrt(np.mean((np.array(test1['visitors'])-np.array(pred_Exp))**2))\n",
        "print(rmse_Exp)\n",
        "plt.figure(figsize = (6,3))\n",
        "pred_Exp.plot()\n",
        "test1['visitors'].plot()\n",
        "plt.legend(['predicted', 'actual'],loc = (0.75,0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ef283a",
      "metadata": {
        "id": "56ef283a"
      },
      "outputs": [],
      "source": [
        "#Multiplicative Additive Seasonality\n",
        "Mul_Add_sea = smf.ols('log_visitors~t+t_sq+month+day',data = train1).fit()\n",
        "pred_Mult_add_sea = pd.Series(Mul_Add_sea.predict(test1))\n",
        "rmse_Mult_add_sea = np.sqrt(np.mean((np.array(test1['visitors'])-np.array(pred_Mult_add_sea))**2))\n",
        "print(rmse_Mult_add_sea)\n",
        "plt.figure(figsize = (6,3))\n",
        "pred_Mult_add_sea.plot()\n",
        "test1['visitors'].plot()\n",
        "plt.legend(['predicted', 'actual'],loc = (0.75,0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0af6b8c1",
      "metadata": {
        "id": "0af6b8c1"
      },
      "outputs": [],
      "source": [
        "# Holt method\n",
        "from statsmodels.tsa.holtwinters import Holt\n",
        "hw_model = Holt(train).fit(smoothing_level=0.8, smoothing_trend=0.2)\n",
        "pred_hw = hw_model.predict(start = test.index[0],end = test.index[-1])\n",
        "rmse_hw = np.sqrt(np.abs((test-pred_hw)**2)).mean()\n",
        "print(\"rmse:\", rmse_hw)\n",
        "plt.figure(figsize = (6,3))\n",
        "pred_hw.plot()\n",
        "test.plot()\n",
        "plt.legend(['predicted', 'actual'],loc = (0.75,0))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2fa5abb",
      "metadata": {
        "id": "f2fa5abb"
      },
      "outputs": [],
      "source": [
        "# Holts winter exponential smoothing with additive seasonality and additive trend\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "hwe_model_add_add = ExponentialSmoothing(train,seasonal=\"add\",trend=\"add\",seasonal_periods=21).fit() #add the trend to the model\n",
        "pred_hwe_add_add = hwe_model_add_add.predict(start = test.index[0],end = test.index[-1])\n",
        "rmse_hw_add_add = np.sqrt(np.abs((test-pred_hwe_add_add)**2)).mean()\n",
        "print(\"rmse:\", rmse_hw_add_add)\n",
        "plt.figure(figsize = (6,3))\n",
        "pred_hwe_add_add.plot()\n",
        "test.plot()\n",
        "plt.legend(['predicted', 'actual'],loc = (0.75,0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d679a1a0",
      "metadata": {
        "id": "d679a1a0"
      },
      "outputs": [],
      "source": [
        "#Holts winter exponential smoothing with multiplicative seasonality and additive trend\n",
        "hwe_model_mul_add = ExponentialSmoothing(train,seasonal=\"mul\",trend=\"add\",seasonal_periods=21).fit()\n",
        "pred_hwe_mul_add = hwe_model_mul_add.predict(start = test.index[0],end = test.index[-1])\n",
        "rmse_hw_mul_add = np.sqrt(np.abs((test-pred_hwe_mul_add)**2)).mean()\n",
        "print(\"rmse:\", rmse_hw_mul_add)\n",
        "plt.figure(figsize = (6,3))\n",
        "pred_hwe_mul_add.plot()\n",
        "test.plot()\n",
        "plt.legend(['predicted', 'actual'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dffd7109",
      "metadata": {
        "id": "dffd7109"
      },
      "outputs": [],
      "source": [
        "# Auto regression model\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from numpy import sqrt\n",
        "# contrived dataset\n",
        "# fit model\n",
        "model = AutoReg(train, lags=18)\n",
        "model_fit = model.fit()\n",
        "# make prediction\n",
        "yhat = model_fit.predict(start = test.index[0],end = test.index[-1], dynamic=False)\n",
        "rmse_AR = np.sqrt(np.abs((test-yhat)**2)).mean()\n",
        "print(\"rmse:\", rmse_AR)\n",
        "plt.figure(figsize = (6,3))\n",
        "yhat.plot()\n",
        "test.plot()\n",
        "plt.legend(['predicted', 'actual'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9909c0e",
      "metadata": {
        "id": "d9909c0e"
      },
      "source": [
        "# ARIMA: Auto Regressive Integrated Moving Average model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c90e813c",
      "metadata": {
        "id": "c90e813c"
      },
      "outputs": [],
      "source": [
        "# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\n",
        "def evaluate_arima_model(X, arima_order):\n",
        "# prepare training dataset\n",
        "    history = [x for x in train]\n",
        "    predictions = []\n",
        "    for t in range(len(test)):\n",
        "        model = ARIMA(history, order=arima_order)\n",
        "        model_fit = model.fit()\n",
        "        yhat = model_fit.forecast()[0]\n",
        "        predictions.append(yhat)\n",
        "        history.append(test[t])\n",
        "# calculate out of sample error\n",
        "    rmse = sqrt(mean_squared_error(test, predictions))\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df0dada3",
      "metadata": {
        "id": "df0dada3"
      },
      "outputs": [],
      "source": [
        "# evaluate combinations of p, d and q values for an ARIMA model\n",
        "def evaluate_models(dataset, p_values, d_values, q_values):\n",
        "    dataset = dataset.astype('float32')\n",
        "    best_score, best_cfg = float('inf'), None\n",
        "    for p in p_values:\n",
        "        for d in d_values:\n",
        "            for q in q_values:\n",
        "                order = (p,d,q)\n",
        "                try:\n",
        "                    rmse = evaluate_arima_model(train, order)\n",
        "                    if rmse < best_score:\n",
        "                        best_score, best_cfg = rmse, order\n",
        "                        print('ARIMA%s RMSE=%.3f' % (order,rmse))\n",
        "                except:\n",
        "                    continue\n",
        "    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57c428c7",
      "metadata": {
        "id": "57c428c7"
      },
      "source": [
        "# evaluate parameters\n",
        "p_values = range(1, 5)\n",
        "d_values = range(0, 5)\n",
        "q_values = range(0, 5)\n",
        "evaluate_models(train1, p_values, d_values, q_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b69e7f",
      "metadata": {
        "id": "f3b69e7f"
      },
      "outputs": [],
      "source": [
        "#ARIMA (rolling forcast ARIMA model)\n",
        "history = [n for n in train]\n",
        "predictions = []\n",
        "future_steps = len(test)\n",
        "#walk forward validation\n",
        "for t in range(len(test)):\n",
        "    model = ARIMA(history, order=(3,0,4))\n",
        "    model_fit = model.fit()\n",
        "    output = model_fit.forecast()\n",
        "    yhat = output[0]\n",
        "    predictions.append(yhat)\n",
        "    history.append(output[0])\n",
        "rmse_rolling_ARIMA = sqrt(mean_squared_error(test, predictions))\n",
        "print(rmse_arima)\n",
        "plt.plot(test.values)\n",
        "plt.plot(predictions, color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2f5054",
      "metadata": {
        "id": "1f2f5054"
      },
      "outputs": [],
      "source": [
        "#SARIMA model\n",
        "smodel = pm.auto_arima(X, start_p=1, start_q=1,\n",
        "                         test='adf',\n",
        "                         max_p=5, max_q=5, m=7,\n",
        "                         start_P=0, seasonal=True,\n",
        "                         d=None, D=1, trace=True,\n",
        "                         error_action='ignore',\n",
        "                         suppress_warnings=True,\n",
        "                         stepwise=True)\n",
        "\n",
        "smodel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c75740d",
      "metadata": {
        "scrolled": false,
        "id": "0c75740d"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "# rolling sarima forecast\n",
        "x = X.values\n",
        "size = int(len(x) * 0.66)\n",
        "train, test = x[0:size], x[size:len(x)]\n",
        "history = [n for n in train]\n",
        "predictions = list()\n",
        "future_steps = len(test)\n",
        "# ARIMA with walk-forward validation\n",
        "for t in range(future_steps):\n",
        "    model = model=sm.tsa.statespace.SARIMAX(history, order=(3,0,0), seasonal_order=(1,1,2,7))\n",
        "    model_fit = model.fit()\n",
        "    output = model_fit.forecast()\n",
        "    yhat = output[0]\n",
        "    predictions.append(yhat)\n",
        "    history.append(output[0])\n",
        "\n",
        "# evaluate forecasts\n",
        "rmse_rollong_SARIMA = np.sqrt(mean_squared_error(test, predictions))\n",
        "print('Test RMSE: %.3f' % rmse_rollong_SARIMA)\n",
        "\n",
        "# make as panda series\n",
        "fc_series = pd.Series(predictions, index=list(range(len(train), len(history))))\n",
        "test_series = pd.Series(test, index=list(range(len(train), len(history))))\n",
        "\n",
        "# plot forecasts against actual outcomes\n",
        "plt.figure(figsize = (10,4))\n",
        "plt.plot(train,color='black')\n",
        "plt.plot(test_series)\n",
        "plt.plot(fc_series, color='red')\n",
        "plt.legend(['train','test','predicted'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e6b86ea",
      "metadata": {
        "id": "3e6b86ea"
      },
      "source": [
        "# LSTM forcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e668fb79",
      "metadata": {
        "id": "e668fb79"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "size = int(len(df1) * 0.70)\n",
        "X=df1[['visitors']]\n",
        "train, test = X.iloc[0:size], X.iloc[size:len(X)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf82ae08",
      "metadata": {
        "id": "cf82ae08"
      },
      "outputs": [],
      "source": [
        "def forecast(model, history, n_input):\n",
        "    data = np.array(history)\n",
        "    # retrieve last observations for input data\n",
        "    input_x = data[-n_input:,0]\n",
        "    # reshape into [1, n_input, 1]\n",
        "    input_x = input_x.reshape((1, len(input_x), 1))\n",
        "    # forecast the next week\n",
        "    yhat = model.predict(input_x, verbose=0)\n",
        "    # we only want the vector forecast\n",
        "    yhat = yhat[0]\n",
        "    return yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b3fc74",
      "metadata": {
        "scrolled": false,
        "id": "82b3fc74"
      },
      "outputs": [],
      "source": [
        "n_input=20\n",
        "n_features = 1\n",
        "generator = TimeseriesGenerator(train.values,\n",
        "                                train.values,\n",
        "                                length=n_input,\n",
        "                                batch_size=1)\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100,activation=\"relu\",input_shape=(n_input, n_features)))\n",
        "model.add(Dense(1),)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "# fit model\n",
        "model.fit_generator(generator, steps_per_epoch=1, epochs=200, verbose=0)\n",
        "\n",
        "# make a forecast\n",
        "history = [n for n in train.values]\n",
        "predictions = list()\n",
        "for i in range(len(test.values)):\n",
        "    yhat_sequence = forecast(model, history, n_input)\n",
        "    # store the predictions\n",
        "    predictions.append(yhat_sequence[0])\n",
        "    # get the forecatsed value and add to history for next day forcast\n",
        "    history.append(yhat_sequence)\n",
        "\n",
        "res_LSTM = pd.DataFrame(test.values)\n",
        "res_LSTM[\"predicted\"] = predictions\n",
        "res_LSTM.columns = [\"actual\",\"predicted\"]\n",
        "rmse_LSTM = sqrt(mean_squared_error(res_LSTM[\"actual\"], res_LSTM[\"predicted\"]))\n",
        "print(\"rmse :\",rmse_LSTM)\n",
        "plt.figure(figsize = (6,3))\n",
        "res_LSTM[\"actual\"].plot()\n",
        "res_LSTM[\"predicted\"].plot()\n",
        "plt.legend(['actual', 'predicted'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82fb0a10",
      "metadata": {
        "id": "82fb0a10"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b923a90",
      "metadata": {
        "scrolled": false,
        "id": "0b923a90"
      },
      "outputs": [],
      "source": [
        "model_evaluation = {'Quadratic':rmse_Quad,'exponential':rmse_Exp,'hw': rmse_hw,'hw_add_add':rmse_hw_add_add,'hw_mul_add':rmse_hw_mul_add,'auto_regression':rmse_AR,\n",
        "                    'rolling_ARIMA':rmse_rolling_ARIMA,'rolling_SARIMA': rmse_rollong_SARIMA,'LSTM':rmse_LSTM}\n",
        "results = pd.DataFrame(data = model_evaluation, index = range(1)).T.reset_index()\n",
        "results.columns = ['model','RMSE']\n",
        "results = results.sort_values(by='RMSE')\n",
        "plt.figure(figsize=(8,3))\n",
        "ax = sns.barplot(x = results.model,y=results.RMSE, data=results)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.ylim(0,3200)\n",
        "for i in ax.containers:\n",
        "    ax.bar_label(i,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a38835a3",
      "metadata": {
        "id": "a38835a3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5b230b76",
      "metadata": {
        "id": "5b230b76"
      },
      "source": [
        "# Final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e62a75",
      "metadata": {
        "id": "c6e62a75"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}